{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKChurn model \n",
    "### Team members: Lorena Mejía, Alfredo Carrillo and Ricardo Figueroa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the spark application called 'KKchurn' to use all the available cores\n",
    "conf = SparkConf().setAppName('KKChurn').setMaster(\"local[*]\").set(\"spark.driver.maxResultSize\", \"6g\")\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transactions file using Pyspark\n",
    "transactions=sc.textFile('./data/transactions.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "transactions=transactions.toDF(transactions.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transactions_v2 file using Pyspark\n",
    "transactions_2=sc.textFile('./data/churn_comp_refresh/train_v2.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "transactions_2=transactions_2.toDF(transactions_2.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train data (before updates)\n",
    "train_data=sc.textFile('./data/train.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "train_data=train_data.toDF(train_data.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train data v2 \n",
    "train_data_2=sc.textFile('./data/churn_comp_refresh/train_v2.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "train_data_2=train_data_2.toDF(train_data_2.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_zero = sc.textFile('./data/sample_submission_zero.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "sample_submission_zero=sample_submission_zero.toDF(sample_submission_zero.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_2 = sc.textFile('./data/churn_comp_refresh/sample_submission_v2.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "sample_submission_2=sample_submission_2.toDF(sample_submission_2.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs = sc.textFile('./data/user_logs.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "user_logs = user_logs.toDF(user_logs.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs = sc.textFile('./data/user_logs.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "user_logs = user_logs.toDF(user_logs.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+------+------+-------+-------+-------+----------+\n",
      "|                msno|    date|num_25|num_50|num_75|num_985|num_100|num_unq|total_secs|\n",
      "+--------------------+--------+------+------+------+-------+-------+-------+----------+\n",
      "|                msno|    date|num_25|num_50|num_75|num_985|num_100|num_unq|total_secs|\n",
      "|rxIP2f2aN0rYNp+to...|20150513|     0|     0|     0|      0|      1|      1|  280.3350|\n",
      "|rxIP2f2aN0rYNp+to...|20150709|     9|     1|     0|      0|      7|     11| 1658.9480|\n",
      "|yxiEWwE9VR5utpUec...|20150105|     3|     3|     0|      0|     68|     36|17364.9560|\n",
      "|yxiEWwE9VR5utpUec...|20150306|     1|     0|     1|      1|     97|     27|24667.3170|\n",
      "|yxiEWwE9VR5utpUec...|20150501|     3|     0|     0|      0|     38|     38| 9649.0290|\n",
      "|yxiEWwE9VR5utpUec...|20150702|     4|     0|     1|      1|     33|     10|10021.5200|\n",
      "|yxiEWwE9VR5utpUec...|20150830|     3|     1|     0|      0|      4|      7| 1119.5550|\n",
      "|yxiEWwE9VR5utpUec...|20151107|     1|     0|     0|      0|      4|      5|  938.0220|\n",
      "|yxiEWwE9VR5utpUec...|20160110|     2|     0|     1|      0|     11|      6| 3004.0680|\n",
      "|yxiEWwE9VR5utpUec...|20160316|     9|     3|     4|      1|     67|     50|18257.6610|\n",
      "|yxiEWwE9VR5utpUec...|20160510|     5|     3|     2|      1|     67|     66|16764.2060|\n",
      "|yxiEWwE9VR5utpUec...|20160804|     1|     4|     5|      0|     36|     43|11359.5650|\n",
      "|yxiEWwE9VR5utpUec...|20160926|     7|     1|     0|      1|     38|     20|10201.9790|\n",
      "|yxiEWwE9VR5utpUec...|20161115|     0|     1|     4|      1|     38|     40| 9288.9480|\n",
      "|yxiEWwE9VR5utpUec...|20170106|     0|     0|     0|      1|     39|     38|10123.2280|\n",
      "|PNxIsSLWOJDCm7pNP...|20151201|     3|     3|     2|      0|      8|     11| 2293.2500|\n",
      "|PNxIsSLWOJDCm7pNP...|20160628|     0|     0|     1|      1|      1|      3|  639.0300|\n",
      "|PNxIsSLWOJDCm7pNP...|20170106|     2|     1|     0|      0|     35|     34| 7563.9360|\n",
      "|KXF9c/T66LZIzFq+x...|20150803|     0|     0|     0|      0|     16|     11| 3585.9400|\n",
      "+--------------------+--------+------+------+------+-------+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example to show a dataframe from Spark\n",
    "user_logs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_logs_2 = sc.textFile('./data/churn_comp_refresh/sample_submission_v2.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "user_logs_2 = user_logs_2.toDF(user_logs_2.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = sc.textFile('./data/members_v3.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "members = members.toDF(members.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                msno|\n",
      "+--------------------+\n",
      "|                msno|\n",
      "|YyO+tlZtAXYXoZhNr...|\n",
      "|AZtu6Wl0gPojrEQYB...|\n",
      "|UkDFI97Qb6+s2LWci...|\n",
      "|M1C56ijxozNaGD0t2...|\n",
      "|yvj6zyBUaqdbUQSrK...|\n",
      "|KN7I82kjY0Tn76Ny9...|\n",
      "|m5ptKif9BjdUghHXX...|\n",
      "|uQxbyACsPOEkTIrv9...|\n",
      "|LUPRfoE2r3WwVWhYO...|\n",
      "|pMVjPLgVknaJYm9L0...|\n",
      "|bQkbrEPdMfVfdsoz0...|\n",
      "|TZVCT9pCufI/AWjrG...|\n",
      "|b2AiGMFhT6fbDyN12...|\n",
      "|ksInNb4D5jdSSIYUr...|\n",
      "|aQKXNflQtXF92cpv4...|\n",
      "|iFxPpElVK6kXnZbuh...|\n",
      "|8qrtRZQTuCih4YJhj...|\n",
      "|pE2FeJOBZv5snDGdF...|\n",
      "|vma4rQzDa/l4Wb/My...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of a query using pyspark\n",
    "aggr_value = transactions.select(\"msno\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hisds', 'sdfs']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Util functions \n",
    "def splitComma(line:str):\n",
    "    splits = COMMA_DELIMITER.split(line)\n",
    "    return \"{}, {}\".format(splits[1], splits[6])\n",
    "def comma_delimiter(line):\n",
    "    return(line.split(','))\n",
    "COMMA_DELIMITER = re.compile(''', (?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)''')\n",
    "COMMA_DELIMITER.split(\"hisds, sdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to save to a text file \n",
    "# transactions.map(lambda row: str(row[0]) + \"\\t\" + str(row[1])) \\\n",
    "#    .saveAsTextFile(\"out/try2.text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos función para importar datos\n",
    "def import_csv(file):\n",
    "    temp_data = []\n",
    "    with open(file,'rt', encoding='ASCII') as csvfile: \n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|') \n",
    "        for row in reader:\n",
    "            temp_data.append(row)\n",
    "    temp_data = np.array(temp_data)\n",
    "    return(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función para limpiar los datos del train y test data\n",
    "def limpiar_train_test(np_array):\n",
    "    np_array = np.array([[np_array[i][0].replace(\"=\", \"\"), np_array[i][1]] for i in range(len(np_array))])\n",
    "    return(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y Test Data\n",
    "The train and test set, containing the user ids and whether they have churned. \n",
    "- msno: user id\n",
    "- is_churn: This is the target variable. Churn is defined as whether the user did not continue the subscription within 30 days of expiration. is_churn = 1 means churn,is_churn = 0 means renewal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions Data\n",
    "The information and variables included in this file are the following:\n",
    "- MSNO: id of the user\n",
    "- payment_method_id: payment method\n",
    "- payment_plan_days: length of membership plan in days\n",
    "- plan_list_price: in New Taiwan Dollar (NTD)\n",
    "- actual_amount_paid: in New Taiwan Dollar (NTD)\n",
    "- is_auto_renew\n",
    "- transaction_date: format %Y%m%d\n",
    "- membership_expire_date: format %Y%m%d\n",
    "- is_cancel: whether or not the user canceled the membership in this transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User logs\n",
    "Daily user logs describing listening behaviors of a user. Data collected until 2/28/2017. \n",
    "The information and variables included in this file are the following:\n",
    "- msno: user id\n",
    "- date: format %Y%m%d\n",
    "- num_25: # of songs played less than 25% of the song length\n",
    "- num_50: # of songs played between 25% to 50% of the song length\n",
    "- num_75: # of songs played between 50% to 75% of of the song length\n",
    "- num_985: # of songs played between 75% to 98.5% of the song length\n",
    "- num_100: # of songs played over 98.5% of the song length\n",
    "- num_unq: # of unique songs played"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Members\n",
    "User information\n",
    "The information and variables included in this file are the following:\n",
    "- msno: user id\n",
    "- date: format %Y%m%d\n",
    "- num_25: # of songs played less than 25% of the song length\n",
    "- num_50: # of songs played between 25% to 50% of the song length\n",
    "- num_75: # of songs played between 50% to 75% of of the song length\n",
    "- num_985: # of songs played between 75% to 98.5% of the song length\n",
    "- num_100: # of songs played over 98.5% of the song length\n",
    "- num_unq: # of unique songs played"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
